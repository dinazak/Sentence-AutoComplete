{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "aihR9yzezUyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import gensim\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from keras.utils import to_categorical\n",
        "import re\n",
        "\n",
        "# Use the filterwarnings() function to ignore warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "lX6BUbck4aAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVb9hD68Hiak",
        "outputId": "6ae6221d-d2ba-4479-962c-fa1dd61d59b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Data**"
      ],
      "metadata": {
        "id": "T817KTd7ze-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to the enronsent.zip file\n",
        "zip_file_path = '/content/drive/MyDrive/enronsent.zip'\n",
        "\n",
        "# Open the zip file and get the list of file names\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    file_list = zip_ref.namelist()"
      ],
      "metadata": {
        "id": "tz9sbYWC4b0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty string to store the concatenated file contents\n",
        "concatenated_content_training = ''\n",
        "\n",
        "# Open the zip file again to read the file contents\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Iterate through the first 10 files in the file list\n",
        "    for file_path in file_list[0:11]:\n",
        "        # Read the file contents as binary data\n",
        "        with zip_ref.open(file_path) as file:\n",
        "            file_content = file.read()\n",
        "\n",
        "        # Decode the file content from bytes to string\n",
        "        decoded_content = file_content.decode('utf-8', errors='replace')\n",
        "\n",
        "        # Concatenate the file content to the existing string\n",
        "        concatenated_content_training += decoded_content\n",
        "len(concatenated_content_training)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoldXS1yEZwd",
        "outputId": "589166c4-7805-474a-ccb5-3b74a7ab08d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23890105"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty string to store the concatenated file contents\n",
        "concatenated_content_validation = ''\n",
        "\n",
        "# Open the zip file again to read the file contents\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Iterate through the first 10 files in the file list\n",
        "    for file_path in file_list[11:16]:\n",
        "        # Read the file contents as binary data\n",
        "        with zip_ref.open(file_path) as file:\n",
        "            file_content = file.read()\n",
        "\n",
        "        # Decode the file content from bytes to string\n",
        "        decoded_content = file_content.decode('utf-8', errors='replace')\n",
        "\n",
        "        # Concatenate the file content to the existing string\n",
        "        concatenated_content_validation += decoded_content\n",
        "len(concatenated_content_validation)"
      ],
      "metadata": {
        "id": "hTpa9UTxIMTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fa1236-890e-44f7-c86f-1c0bf2539c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9490330"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ],
      "metadata": {
        "id": "8SKbfkmmzmfS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCA8pD05jGB5"
      },
      "outputs": [],
      "source": [
        "# Remove non-alphabetic characters\n",
        "cleaned_content_training = re.sub(r'[^a-zA-Z\\s]', '', concatenated_content_training)\n",
        "\n",
        "\n",
        "# Remove URLs\n",
        "cleaned_content_training = re.sub(r'http\\S+|www\\S+', '', cleaned_content_training)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove non-alphabetic characters\n",
        "cleaned_content_validation = re.sub(r'[^a-zA-Z\\s]', '', concatenated_content_validation)\n",
        "\n",
        "# Remove URLs\n",
        "cleaned_conten_validation = re.sub(r'http\\S+|www\\S+', '', cleaned_content_validation)\n",
        "\n"
      ],
      "metadata": {
        "id": "bSwdM1uAFN-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3sCwwPGkU-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89b9636-6e9c-41eb-bb29-da72b496be8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128184"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Split the cleaned_content into paragraphs\n",
        "paragraphs = cleaned_content_training.split(\"\\n\\n\")\n",
        "\n",
        "# Convert paragraphs to a list\n",
        "paragraph_list_training = list(filter(None, paragraphs))\n",
        "paragraph_list_training=[re.sub('\\s+', ' ', paragraph) for paragraph in paragraph_list_training]\n",
        "len(paragraph_list_training)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the cleaned_content into paragraphs\n",
        "paragraphs = cleaned_content_validation.split(\"\\n\\n\")\n",
        "\n",
        "# Convert paragraphs to a list\n",
        "paragraph_list_validation = list(filter(None, paragraphs))\n",
        "paragraph_list_validation=[re.sub('\\s+', ' ', paragraph) for paragraph in paragraph_list_validation]\n",
        "len(paragraph_list_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDKrffz9FwQS",
        "outputId": "e73589f7-6791-4056-9bb0-0db227cd8b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63276"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9DdB7dSYmO4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8dba5a01-a031-47c5-a9c1-88d2934018b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Attached are two files that illustrate the following'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "paragraph_list_training[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph_list_validation[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SqZlvXBSGBu8",
        "outputId": "8dfbd995-db77-4601-8d29-3b8acd77b1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for how we are going to play these different opportunities off of one another '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMFPfdCbZPet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b07c594-f871-494f-c036-5e198d82ef57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74737\n",
            "13179\n"
          ]
        }
      ],
      "source": [
        "def split_paragraph_into_time_steps(paragraph, time_steps):\n",
        "    words = paragraph.split()\n",
        "    data=[]\n",
        "    for i in range( len(words)-time_steps):\n",
        "      data.append(words[i:i+time_steps])\n",
        "\n",
        "    return data\n",
        "\n",
        "time_steps = 10  # Assuming each time step contains 25 words\n",
        "num_training_paragraphs = 5000\n",
        "num_validation_paragraphs = 1000\n",
        "\n",
        "# Select paragraphs for training\n",
        "training_paragraphs = paragraph_list_training[:num_training_paragraphs]\n",
        "training_time_steps = []\n",
        "for paragraph in training_paragraphs:\n",
        "    time_steps_list = split_paragraph_into_time_steps(paragraph, time_steps)\n",
        "    training_time_steps.extend(time_steps_list)\n",
        "\n",
        "# Select paragraphs for validation\n",
        "validation_paragraphs = paragraph_list_validation[num_training_paragraphs:num_training_paragraphs+num_validation_paragraphs]\n",
        "validation_time_steps = []\n",
        "for paragraph in validation_paragraphs:\n",
        "    time_steps_list = split_paragraph_into_time_steps(paragraph, time_steps)\n",
        "    validation_time_steps.extend(time_steps_list)\n",
        "\n",
        "print(len(training_time_steps))\n",
        "print(len(validation_time_steps))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbSNKG-r4fZf"
      },
      "outputs": [],
      "source": [
        "training_time_steps=np.array(training_time_steps)\n",
        "validation_time_steps=np.array(validation_time_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaNoioNR4m0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0fbf28-216e-42b8-aa54-18557f10c528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(74737, 10) (13179, 10)\n"
          ]
        }
      ],
      "source": [
        "print(training_time_steps.shape,validation_time_steps.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec model**"
      ],
      "metadata": {
        "id": "tOaYsSVmzvj4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5m3TaG_qw-j",
        "outputId": "1bf41964-7710-4ed4-a7f2-6b181e63fee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=paragraph_list_training, vector_size=300, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"word2vec.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "# Convert sentences to sequences of word indices\n",
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(training_time_steps.tolist())  # Convert to list before fitting\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(training_time_steps.tolist())\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "# Split into input (X) and target (y)\n",
        "X = padded_sequences[:, :-1]\n",
        "y = padded_sequences[:, -1]\n",
        "\n",
        "# Convert validation data to sequences\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_time_steps.tolist())\n",
        "validation_padded_sequences = pad_sequences(validation_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "# Split into validation input (X_val) and target (y_val)\n",
        "X_val = validation_padded_sequences[:, :-1]\n",
        "y_val = validation_padded_sequences[:, -1]\n",
        "\n",
        "# Define the LSTM model\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_sequence_length-1))\n",
        "model.add(keras.layers.LSTM(100))\n",
        "model.add(keras.layers.Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the LSTM model\n",
        "model.fit(X, y, validation_data=(X_val, y_val), epochs=100, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y63jqGssJVqF",
        "outputId": "ce58cb19-e96c-4291-d23e-d7e2f8d23349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2336/2336 [==============================] - 33s 12ms/step - loss: 6.7773 - accuracy: 0.0683 - val_loss: 6.3048 - val_accuracy: 0.0813\n",
            "Epoch 2/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 6.0231 - accuracy: 0.1075 - val_loss: 6.1123 - val_accuracy: 0.1052\n",
            "Epoch 3/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 5.4998 - accuracy: 0.1371 - val_loss: 6.1209 - val_accuracy: 0.1076\n",
            "Epoch 4/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 5.0153 - accuracy: 0.1718 - val_loss: 6.1903 - val_accuracy: 0.1125\n",
            "Epoch 5/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 4.5605 - accuracy: 0.2122 - val_loss: 6.3192 - val_accuracy: 0.1086\n",
            "Epoch 6/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 4.1350 - accuracy: 0.2596 - val_loss: 6.4816 - val_accuracy: 0.1084\n",
            "Epoch 7/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 3.7381 - accuracy: 0.3095 - val_loss: 6.6838 - val_accuracy: 0.1071\n",
            "Epoch 8/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 3.3722 - accuracy: 0.3627 - val_loss: 6.8642 - val_accuracy: 0.1008\n",
            "Epoch 9/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 3.0371 - accuracy: 0.4179 - val_loss: 7.0536 - val_accuracy: 0.1033\n",
            "Epoch 10/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 2.7301 - accuracy: 0.4703 - val_loss: 7.2216 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 2.4543 - accuracy: 0.5197 - val_loss: 7.4025 - val_accuracy: 0.1008\n",
            "Epoch 12/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 2.2079 - accuracy: 0.5668 - val_loss: 7.6209 - val_accuracy: 0.0969\n",
            "Epoch 13/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 1.9860 - accuracy: 0.6065 - val_loss: 7.7973 - val_accuracy: 0.0982\n",
            "Epoch 14/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 1.7908 - accuracy: 0.6447 - val_loss: 8.0161 - val_accuracy: 0.0892\n",
            "Epoch 15/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 1.6148 - accuracy: 0.6773 - val_loss: 8.2114 - val_accuracy: 0.0876\n",
            "Epoch 16/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 1.4583 - accuracy: 0.7090 - val_loss: 8.4132 - val_accuracy: 0.0863\n",
            "Epoch 17/100\n",
            "2336/2336 [==============================] - 17s 7ms/step - loss: 1.3144 - accuracy: 0.7375 - val_loss: 8.6399 - val_accuracy: 0.0862\n",
            "Epoch 18/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 1.1908 - accuracy: 0.7620 - val_loss: 8.8214 - val_accuracy: 0.0851\n",
            "Epoch 19/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 1.0773 - accuracy: 0.7840 - val_loss: 9.0208 - val_accuracy: 0.0835\n",
            "Epoch 20/100\n",
            "2336/2336 [==============================] - 14s 6ms/step - loss: 0.9757 - accuracy: 0.8065 - val_loss: 9.2103 - val_accuracy: 0.0836\n",
            "Epoch 21/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.8860 - accuracy: 0.8228 - val_loss: 9.4463 - val_accuracy: 0.0814\n",
            "Epoch 22/100\n",
            "2336/2336 [==============================] - 21s 9ms/step - loss: 0.8013 - accuracy: 0.8416 - val_loss: 9.5809 - val_accuracy: 0.0808\n",
            "Epoch 23/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.7329 - accuracy: 0.8536 - val_loss: 9.8071 - val_accuracy: 0.0782\n",
            "Epoch 24/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.6653 - accuracy: 0.8689 - val_loss: 9.9795 - val_accuracy: 0.0766\n",
            "Epoch 25/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.6079 - accuracy: 0.8800 - val_loss: 10.2136 - val_accuracy: 0.0775\n",
            "Epoch 26/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.5541 - accuracy: 0.8914 - val_loss: 10.3906 - val_accuracy: 0.0779\n",
            "Epoch 27/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.5114 - accuracy: 0.9004 - val_loss: 10.5061 - val_accuracy: 0.0750\n",
            "Epoch 28/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.4704 - accuracy: 0.9078 - val_loss: 10.7052 - val_accuracy: 0.0757\n",
            "Epoch 29/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.4323 - accuracy: 0.9163 - val_loss: 10.8855 - val_accuracy: 0.0736\n",
            "Epoch 30/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.3963 - accuracy: 0.9236 - val_loss: 11.0225 - val_accuracy: 0.0800\n",
            "Epoch 31/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.3669 - accuracy: 0.9290 - val_loss: 11.2196 - val_accuracy: 0.0735\n",
            "Epoch 32/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.3415 - accuracy: 0.9348 - val_loss: 11.3702 - val_accuracy: 0.0737\n",
            "Epoch 33/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.3168 - accuracy: 0.9392 - val_loss: 11.5058 - val_accuracy: 0.0763\n",
            "Epoch 34/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.2948 - accuracy: 0.9433 - val_loss: 11.6869 - val_accuracy: 0.0709\n",
            "Epoch 35/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.2755 - accuracy: 0.9474 - val_loss: 11.8278 - val_accuracy: 0.0706\n",
            "Epoch 36/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.2605 - accuracy: 0.9498 - val_loss: 11.9569 - val_accuracy: 0.0713\n",
            "Epoch 37/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.2456 - accuracy: 0.9532 - val_loss: 12.0852 - val_accuracy: 0.0717\n",
            "Epoch 38/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.2277 - accuracy: 0.9565 - val_loss: 12.2108 - val_accuracy: 0.0690\n",
            "Epoch 39/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.2186 - accuracy: 0.9579 - val_loss: 12.3658 - val_accuracy: 0.0730\n",
            "Epoch 40/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.2052 - accuracy: 0.9612 - val_loss: 12.4410 - val_accuracy: 0.0698\n",
            "Epoch 41/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.1973 - accuracy: 0.9621 - val_loss: 12.5768 - val_accuracy: 0.0691\n",
            "Epoch 42/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1886 - accuracy: 0.9638 - val_loss: 12.7115 - val_accuracy: 0.0726\n",
            "Epoch 43/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1761 - accuracy: 0.9668 - val_loss: 12.8314 - val_accuracy: 0.0718\n",
            "Epoch 44/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.1688 - accuracy: 0.9672 - val_loss: 12.9171 - val_accuracy: 0.0719\n",
            "Epoch 45/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.1641 - accuracy: 0.9687 - val_loss: 13.0218 - val_accuracy: 0.0712\n",
            "Epoch 46/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1623 - accuracy: 0.9676 - val_loss: 13.1273 - val_accuracy: 0.0722\n",
            "Epoch 47/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1512 - accuracy: 0.9703 - val_loss: 13.2256 - val_accuracy: 0.0700\n",
            "Epoch 48/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1444 - accuracy: 0.9723 - val_loss: 13.3134 - val_accuracy: 0.0709\n",
            "Epoch 49/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1468 - accuracy: 0.9700 - val_loss: 13.4399 - val_accuracy: 0.0701\n",
            "Epoch 50/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1367 - accuracy: 0.9734 - val_loss: 13.5320 - val_accuracy: 0.0686\n",
            "Epoch 51/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1363 - accuracy: 0.9730 - val_loss: 13.5962 - val_accuracy: 0.0694\n",
            "Epoch 52/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.1274 - accuracy: 0.9752 - val_loss: 13.6768 - val_accuracy: 0.0728\n",
            "Epoch 53/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.1298 - accuracy: 0.9739 - val_loss: 13.7550 - val_accuracy: 0.0696\n",
            "Epoch 54/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1235 - accuracy: 0.9757 - val_loss: 13.8324 - val_accuracy: 0.0701\n",
            "Epoch 55/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1257 - accuracy: 0.9745 - val_loss: 13.9409 - val_accuracy: 0.0737\n",
            "Epoch 56/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1191 - accuracy: 0.9751 - val_loss: 13.9783 - val_accuracy: 0.0703\n",
            "Epoch 57/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1141 - accuracy: 0.9768 - val_loss: 14.1164 - val_accuracy: 0.0711\n",
            "Epoch 58/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1099 - accuracy: 0.9778 - val_loss: 14.1508 - val_accuracy: 0.0709\n",
            "Epoch 59/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1069 - accuracy: 0.9781 - val_loss: 14.2525 - val_accuracy: 0.0694\n",
            "Epoch 60/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1112 - accuracy: 0.9769 - val_loss: 14.3379 - val_accuracy: 0.0691\n",
            "Epoch 61/100\n",
            "2336/2336 [==============================] - 17s 7ms/step - loss: 0.1022 - accuracy: 0.9789 - val_loss: 14.3909 - val_accuracy: 0.0711\n",
            "Epoch 62/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.1040 - accuracy: 0.9787 - val_loss: 14.5007 - val_accuracy: 0.0714\n",
            "Epoch 63/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1033 - accuracy: 0.9782 - val_loss: 14.5022 - val_accuracy: 0.0663\n",
            "Epoch 64/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.0986 - accuracy: 0.9794 - val_loss: 14.5335 - val_accuracy: 0.0713\n",
            "Epoch 65/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1034 - accuracy: 0.9779 - val_loss: 14.6432 - val_accuracy: 0.0699\n",
            "Epoch 66/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.1000 - accuracy: 0.9786 - val_loss: 14.6682 - val_accuracy: 0.0677\n",
            "Epoch 67/100\n",
            "2336/2336 [==============================] - 17s 7ms/step - loss: 0.0959 - accuracy: 0.9791 - val_loss: 14.7182 - val_accuracy: 0.0694\n",
            "Epoch 68/100\n",
            "2336/2336 [==============================] - 17s 7ms/step - loss: 0.0957 - accuracy: 0.9792 - val_loss: 14.8079 - val_accuracy: 0.0692\n",
            "Epoch 69/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0908 - accuracy: 0.9807 - val_loss: 14.9341 - val_accuracy: 0.0672\n",
            "Epoch 70/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.0933 - accuracy: 0.9790 - val_loss: 14.9245 - val_accuracy: 0.0675\n",
            "Epoch 71/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.0929 - accuracy: 0.9798 - val_loss: 15.0212 - val_accuracy: 0.0675\n",
            "Epoch 72/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.0954 - accuracy: 0.9791 - val_loss: 14.9596 - val_accuracy: 0.0697\n",
            "Epoch 73/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.0890 - accuracy: 0.9807 - val_loss: 15.1478 - val_accuracy: 0.0672\n",
            "Epoch 74/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.0928 - accuracy: 0.9789 - val_loss: 15.0991 - val_accuracy: 0.0716\n",
            "Epoch 75/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.0876 - accuracy: 0.9811 - val_loss: 15.1531 - val_accuracy: 0.0688\n",
            "Epoch 76/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.0887 - accuracy: 0.9800 - val_loss: 15.1922 - val_accuracy: 0.0689\n",
            "Epoch 77/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.0901 - accuracy: 0.9793 - val_loss: 15.2513 - val_accuracy: 0.0692\n",
            "Epoch 78/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0812 - accuracy: 0.9821 - val_loss: 15.2926 - val_accuracy: 0.0719\n",
            "Epoch 79/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0874 - accuracy: 0.9797 - val_loss: 15.3567 - val_accuracy: 0.0744\n",
            "Epoch 80/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0868 - accuracy: 0.9800 - val_loss: 15.4292 - val_accuracy: 0.0701\n",
            "Epoch 81/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0834 - accuracy: 0.9809 - val_loss: 15.4115 - val_accuracy: 0.0743\n",
            "Epoch 82/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.0824 - accuracy: 0.9811 - val_loss: 15.5029 - val_accuracy: 0.0729\n",
            "Epoch 83/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.0859 - accuracy: 0.9797 - val_loss: 15.5184 - val_accuracy: 0.0684\n",
            "Epoch 84/100\n",
            "2336/2336 [==============================] - 17s 7ms/step - loss: 0.0856 - accuracy: 0.9801 - val_loss: 15.5891 - val_accuracy: 0.0708\n",
            "Epoch 85/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0886 - accuracy: 0.9789 - val_loss: 15.5754 - val_accuracy: 0.0714\n",
            "Epoch 86/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.0796 - accuracy: 0.9818 - val_loss: 15.6595 - val_accuracy: 0.0722\n",
            "Epoch 87/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0770 - accuracy: 0.9820 - val_loss: 15.7255 - val_accuracy: 0.0702\n",
            "Epoch 88/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0883 - accuracy: 0.9785 - val_loss: 15.7192 - val_accuracy: 0.0705\n",
            "Epoch 89/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.0791 - accuracy: 0.9814 - val_loss: 15.7812 - val_accuracy: 0.0722\n",
            "Epoch 90/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.0771 - accuracy: 0.9821 - val_loss: 15.7376 - val_accuracy: 0.0713\n",
            "Epoch 91/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0864 - accuracy: 0.9793 - val_loss: 15.7675 - val_accuracy: 0.0723\n",
            "Epoch 92/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0730 - accuracy: 0.9830 - val_loss: 15.7726 - val_accuracy: 0.0731\n",
            "Epoch 93/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0805 - accuracy: 0.9810 - val_loss: 15.8024 - val_accuracy: 0.0682\n",
            "Epoch 94/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0793 - accuracy: 0.9812 - val_loss: 15.8861 - val_accuracy: 0.0700\n",
            "Epoch 95/100\n",
            "2336/2336 [==============================] - 15s 6ms/step - loss: 0.0767 - accuracy: 0.9816 - val_loss: 15.8680 - val_accuracy: 0.0705\n",
            "Epoch 96/100\n",
            "2336/2336 [==============================] - 15s 7ms/step - loss: 0.0803 - accuracy: 0.9803 - val_loss: 15.9559 - val_accuracy: 0.0709\n",
            "Epoch 97/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.0778 - accuracy: 0.9819 - val_loss: 15.9610 - val_accuracy: 0.0728\n",
            "Epoch 98/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.0799 - accuracy: 0.9805 - val_loss: 16.0201 - val_accuracy: 0.0743\n",
            "Epoch 99/100\n",
            "2336/2336 [==============================] - 17s 7ms/step - loss: 0.0739 - accuracy: 0.9824 - val_loss: 16.0163 - val_accuracy: 0.0690\n",
            "Epoch 100/100\n",
            "2336/2336 [==============================] - 16s 7ms/step - loss: 0.0755 - accuracy: 0.9817 - val_loss: 16.0558 - val_accuracy: 0.0735\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f46adcd72b0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(sentence, model, tokenizer):\n",
        "    sequence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    sequence = pad_sequences([sequence], maxlen=max_sequence_length-1, padding='pre')\n",
        "    predicted_index = np.argmax(model.predict(sequence))\n",
        "    predicted_word = tokenizer.index_word[predicted_index]\n",
        "    return predicted_word\n"
      ],
      "metadata": {
        "id": "4J5GXre0L1qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence():\n",
        "    sentence = input(\"Enter Next word (-1 to terminate): \")\n",
        "    predicted_sentence = [sentence]\n",
        "\n",
        "    while sentence != '-1':\n",
        "        next_word = predict_next_word(sentence, model, tokenizer)\n",
        "        answer = input(f\"Is your next word: \\\"{next_word}\\\"?\")\n",
        "        if answer.lower() == 'yes':\n",
        "            sentence += ' ' + next_word\n",
        "            predicted_sentence.append(next_word)\n",
        "        else:\n",
        "            sentence = input(\"Enter next word (-1 to terminate): \")\n",
        "            if sentence != '-1':\n",
        "                predicted_sentence.append(sentence)\n",
        "\n",
        "    final_sentence = ' '.join(predicted_sentence)\n",
        "    final_sentence = final_sentence.replace(' -1', '')\n",
        "    print(\"Your final Sentence is:\", final_sentence)\n",
        "\n",
        "predict_sentence()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwf4LwAxrWwk",
        "outputId": "d74bdc83-5cf7-40ab-9288-5a25f218f109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Next word (-1 to terminate): my\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Is your next word: \"business\"?yes\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Is your next word: \"in\"?yes\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Is your next word: \"seguin\"?no\n",
            "Enter next word (-1 to terminate): cairo\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Is your next word: \"in\"?no\n",
            "Enter next word (-1 to terminate): -1\n",
            "Your final Sentence is: my business in cairo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence():\n",
        "    sentence = input(\"Enter Next word (-1 to terminate): \")\n",
        "    predicted_sentence = [sentence]\n",
        "\n",
        "    while sentence != '-1':\n",
        "        next_word = predict_next_word(sentence, model, tokenizer)\n",
        "        answer = input(f\"Is your next word: \\\"{next_word}\\\"?\")\n",
        "        if answer.lower() == 'yes':\n",
        "            sentence += ' ' + next_word\n",
        "            predicted_sentence.append(next_word)\n",
        "        else:\n",
        "            sentence = input(\"Enter next word (-1 to terminate): \")\n",
        "            if sentence != '-1':\n",
        "                predicted_sentence.append(sentence)\n",
        "\n",
        "    final_sentence = ' '.join(predicted_sentence)\n",
        "    final_sentence = final_sentence.replace(' -1', '')\n",
        "    print(\"Your final Sentence is:\", final_sentence)\n",
        "\n",
        "predict_sentence()"
      ],
      "metadata": {
        "id": "-DM5ED0Q1px-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0055129-9345-4239-d290-5e629114d8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Next word (-1 to terminate): I\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Is your next word: \"am\"?yes\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Is your next word: \"inviting\"?yes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Is your next word: \"less\"?no\n",
            "Enter next word (-1 to terminate): you\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Is your next word: \"in\"?yes\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Is your next word: \"california\"?yes\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Is your next word: \"power\"?no\n",
            "Enter next word (-1 to terminate): -1\n",
            "Your final Sentence is: I am inviting you in california\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence():\n",
        "    sentence = input(\"Enter Next word (-1 to terminate): \")\n",
        "    predicted_sentence = [sentence]\n",
        "\n",
        "    while sentence != '-1':\n",
        "        next_word = predict_next_word(sentence, model, tokenizer)\n",
        "        answer = input(f\"Is your next word: \\\"{next_word}\\\"?\")\n",
        "        if answer.lower() == 'yes':\n",
        "            sentence += ' ' + next_word\n",
        "            predicted_sentence.append(next_word)\n",
        "        else:\n",
        "            sentence = input(\"Enter next word (-1 to terminate): \")\n",
        "            if sentence != '-1':\n",
        "                predicted_sentence.append(sentence)\n",
        "\n",
        "    final_sentence = ' '.join(predicted_sentence)\n",
        "    final_sentence = final_sentence.replace(' -1', '')\n",
        "    print(\"Your final Sentence is:\", final_sentence)\n",
        "\n",
        "predict_sentence()"
      ],
      "metadata": {
        "id": "LNf8B9Cf1qfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50a62fb-4512-4da0-f70f-57dfe55e6fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Next word (-1 to terminate): hello\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Is your next word: \"estimated\"?no\n",
            "Enter next word (-1 to terminate): my\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Is your next word: \"business\"?no\n",
            "Enter next word (-1 to terminate): friends\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Is your next word: \"versus\"?no\n",
            "Enter next word (-1 to terminate): -1\n",
            "Your final Sentence is: hello my friends\n"
          ]
        }
      ]
    }
  ]
}